{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 Homework\n",
    "\n",
    "---\n",
    "\n",
    "### Q1: derive the following\n",
    "\n",
    "1. $p(\\boldsymbol \\beta | \\textbf{y}, \\textbf{X}, \\Sigma=\\sigma^2 I)$ for the **linear regression model** likelihood proportional to $\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top \\Sigma^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)$ and a $\\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta)$ for $\\boldsymbol\\beta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood function for Bayesian linear regression is:\n",
    "\n",
    "$p(y| X, \\beta, \\sigma^2) \\propto exp(-\\frac{1}{2}(y- X\\beta)^T \\Sigma^{-1}(y-X\\beta))$\n",
    "\n",
    "Since $\\Sigma=\\sigma^2 I$, the above gets simplified to\n",
    "\n",
    "$p(y| X, \\beta, \\sigma^2) \\propto exp(-\\frac{1}{2\\sigma^2}(y- X\\beta)^T(y-X\\beta))$\n",
    "\n",
    "If we assume a multivariate normal prior on $\\beta$: $p(\\beta) = \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta)$ that has the density function:\n",
    "\n",
    "$p(\\beta) \\propto exp(-\\frac{1}{2}(\\beta - \\beta_0)^T \\Sigma_{\\beta}^{-1} (\\beta - \\beta_0))$\n",
    "\n",
    "The Bayes theorem states that the posterior is proportional to the product of the likelihood and the prior:\n",
    "\n",
    "\\begin{align*} p(y| X, \\beta, \\sigma^2) &\\propto p(y| X, \\beta, \\sigma^2) p(\\beta) \\\\\n",
    "&\\propto exp(-\\frac{1}{2\\sigma^2}(y- X\\beta)^T(y-X\\beta)) \\cdot exp(-\\frac{1}{2}(\\beta - \\beta_0)^T \\Sigma_{\\beta}^{-1} (\\beta - \\beta_0)) \\end{align*}\n",
    "\n",
    "Combining the exponents we get:\n",
    "\\begin{align*}\n",
    "-\\frac{1}{2} [\\frac{1}{\\sigma^2}(y-X\\beta)^T (y-X\\beta) + (\\beta - \\beta_0)^T \\Sigma_{\\beta}^{-1} (\\beta - \\beta_0)] \\\\\n",
    "-\\frac{1}{2} [\\beta^T (\\frac{1}{\\sigma^2} X^T X + \\Sigma_{\\beta}^{-1})\\beta - 2\\beta^T (\\frac{1}{\\sigma^2} X^T y + \\Sigma_{\\beta}^{-1} \\beta_0)]\n",
    "\\end{align*}\n",
    "\n",
    "Which is the kernel of a multivariate normal distribution\n",
    "\n",
    "$\\beta | y, X, \\sigma^2 \\sim \\mathcal{MVN}(\\mu_{\\beta}, \\Sigma_{\\beta})$\n",
    "\n",
    "$\\Sigma_{\\beta} = (\\frac{1}{\\sigma^2} X^T X + \\Sigma_{\\beta}^{-1})^{-1}$\n",
    "\n",
    "$\\mu_{\\beta} = \\Sigma_{\\beta} (\\frac{1}{\\sigma^2} X^T y + \\Sigma_{\\beta}^{-1} \\beta_0)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. The analytical posterior distribution for $\\sigma^2$ the **error variance** of a **linear regression model** with **design matrix** $\\mathbf{X}$ assuming $\\sigma^2$ has an **inverse-gamma** prior distribution with parameters $\\alpha^*$ and $\\beta^*$ (unrelated to $\\boldsymbol \\beta$).Â·\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume an inverse gamme prior has density\n",
    "\n",
    "$p(\\sigma^2) \\propto (\\sigma^2)^{-(\\alpha^* +1)}exp(-\\frac{\\beta^*}{\\sigma^2})$\n",
    "\n",
    "Then the likelihood function is\n",
    "\n",
    "$p(y | X, \\beta, \\sigma^2) \\propto (\\sigma^2)^{-n/2} exp(-\\frac{1}{2\\sigma^2}(y- X\\beta)^T(y-X\\beta))$\n",
    "\n",
    "Using the Bayes Theorem\n",
    "\\begin{align*}\n",
    "p(\\sigma^2 | y, X) &\\propto p(y | X, \\beta, \\sigma^2) p(\\sigma^2) \\\\\n",
    "&\\propto (\\sigma^2)^{-n/2} exp(-\\frac{1}{2\\sigma^2}(y- X\\beta)^T(y-X\\beta)) \\cdot (\\sigma^2)^{-(\\alpha^* +1)}exp(-\\frac{\\beta^*}{\\sigma^2}) \\\\\n",
    "&\\propto (\\sigma^2)^{-(\\alpha^* + n/2 + 1)} exp(-\\frac{\\beta^* + 1/2(y - X\\beta)^T (y-X\\beta)}{\\sigma^2})\n",
    "\\end{align*}\n",
    "\n",
    "Which can be recognized as the kernel of an inverse gamma distribution\n",
    "\n",
    "$\\sigma^2 | y, X \\sim \\text{Inv-Gamma} (\\alpha^* + n/2, \\beta^* + 1/2(y-X\\beta)^T(y-X\\beta))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q2: perform Bayesian Linear Regression\n",
    "\n",
    "- For any data set you find interesting (perhaps from kaggle.com?)\n",
    "- Use an appropriate non **inverse-gamma** prior for `sigma` \n",
    "- Use `pm.Normal('betas', mu=0, sigma=1, shape=p)` rather than a `pm.MvNormal` alternative\n",
    "- Use `pm.Normal('y', mu=X@betas, sigma=sigma, observed=y)` rather than `pm.MvNormal` alternative\n",
    "- Provide inference with Bayesian posterior analysis and report MCMC diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q3: perform robust Bayesian Linear Regression\n",
    "\n",
    "Let $p(\\tau_i)$ be $\\require{cancel} \\textrm{gamma}\\big(\\tau_i | \\alpha = \\frac{\\nu}{2}, \\overset{\\textrm{rate}\\xcancel{\\textrm{scale}}}{\\beta = \\frac{\\nu}{2}}\\big)$ and let $p(y_i|\\boldsymbol \\beta, \\tau,\\tau_i)$ be $\\mathcal{N}(y_i | \\textbf{X} \\boldsymbol \\beta, \\overset{\\textrm{precision}}{\\tau \\times \\tau_i})$. \n",
    "\n",
    "- Return to your dataset and maniputate it to have some various outliers or find another dataset with some outlier data\n",
    "- Use an appropriate prior for inference on $v$ if you have enough data to do so\n",
    "- Use the posterior distributions of the $\\tau_i$'s to identify data point \"outliers\" \n",
    "- Use the posterior distributions of the $\\sigma_i^{-2} = \\tau \\times \\tau_i$ to create posterior distribuitions of the **influence** (the diagonals of the $H$ \"hat\" matrix $X^\\top (X^\\top D X)^{-1} X$ where $D_{ij}=0$ and $D_{ii} = \\sigma^2_i$) and compare and contras some example \"outlier\" versus \"non outlier\" data points\n",
    "\n",
    "- Provide inference with Bayesian posterior analysis and report MCMC diagnostics\n",
    "\n",
    "#### [Optional] Q3 Extra: measurement error models?\n",
    "\n",
    "What if $\\textbf{x}_i = \\textbf{x}_i^{true} + \\eta_i, \\eta_i \\sim \\mathcal{MVN}(\\textbf{0}, \\Sigma)$ for some kind of measurement error covariance structure $\\Sigma$ and $\\mathcal N (y_i| \\textbf{X}^{true}\\boldsymbol \\beta, \\sigma)$?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
